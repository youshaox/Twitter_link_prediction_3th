{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "nbpresent": {
     "id": "69bdb17f-a906-4327-94dd-12769907d5f3"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "nbpresent": {
     "id": "df29d587-244b-4354-bf61-ed8efcad5457"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"train.txt\", \"r\") as f:\n",
    "     train_data = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "nbpresent": {
     "id": "817127ef-e2f9-4507-baad-6cdb2610dfde"
    }
   },
   "outputs": [],
   "source": [
    "Nodes = []\n",
    "Edges = []\n",
    "for i in range(len(train_data)):\n",
    "    #if i%100 == 0:\n",
    "        #print(i)\n",
    "    nodes_list = [int(n) for n in train_data[i].split()]\n",
    "    for node in nodes_list:\n",
    "        Nodes.append(node)\n",
    "    for node in nodes_list[1:]:\n",
    "        Edges.append((nodes_list[0],node))\n",
    "Nodes = set(Nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "68134c3b-7328-46ae-aad1-4cc32a099f42"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4867136 24004361\n"
     ]
    }
   ],
   "source": [
    "print(len(Nodes), len(Edges))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate negative samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# random choose 20,000 nodes(same as the len of training data)\n",
    "ng_line = random.sample(Nodes, 20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sE = set(Edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name ):\n",
    "    with open( name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def generate_negative_samples():\n",
    "    negative_samples = {}\n",
    "    for l in tqdm(range(len(ng_line))):\n",
    "        source = ng_line[l]\n",
    "        sls = []\n",
    "        for slinks in random.sample(Nodes, 1200):\n",
    "            if not (source, slinks) in sE:\n",
    "                sls.append(slinks)\n",
    "        negative_samples[source] = sls\n",
    "    return negative_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    negative_samples = load_obj(\"train_neg\")\n",
    "except:\n",
    "    negative_samples = generate_negative_samples\n",
    "    save_obj(negative_samples, \"train_neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1671169"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(negative_samples.keys())[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pos_data = load_obj(\"pos_data\")\n",
    "except:\n",
    "    pos_data = [[t,1] for t in Edges]\n",
    "try:\n",
    "    neg_data = load_obj(\"neg_data\")\n",
    "except:\n",
    "    neg_data = []\n",
    "    for k in negative_samples.keys():\n",
    "        for S in negative_samples[k]:\n",
    "            neg_data.append([(k,S), 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "47c47abb-9b14-4719-adc4-79aaee33f8dc"
    }
   },
   "source": [
    "## Build graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "nbpresent": {
     "id": "8e2b1963-bf62-4296-b591-df37d79d41a5"
    }
   },
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "G.add_nodes_from(Nodes)\n",
    "G.add_edges_from(Edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-calculate len, log(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_features = {}\n",
    "for node in list(Nodes):\n",
    "    num_neig = len(sorted(nx.all_neighbors(G, node)))\n",
    "    log_neig = (1. / math.log(num_neig+1)) if num_neig != 0 else 0\n",
    "    neig = sorted(nx.all_neighbors(G, node))\n",
    "    pre_features[node] = [num_neig, log_neig, neig]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 0.7213475204444817, [1247754, 2382107, 4588320]]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_features[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_obj(pre_features,\"pre_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "nbpresent": {
     "id": "ee10f2c7-3e37-4827-a290-cceb6d83b587"
    }
   },
   "outputs": [],
   "source": [
    "#Adamic-Adar similarity\n",
    "def AA(Node1, Node2):\n",
    "    sim = 0.0\n",
    "    n1 = pre_features[Node1]\n",
    "    n2 = pre_features[Node2]\n",
    "    common_neighors = list(set(n1[2]).intersection(n2[2]))\n",
    "    #print(len(common_neighors))\n",
    "    for node in common_neighors:\n",
    "        sim += pre_features[node][1]\n",
    "    return sim\n",
    "\n",
    "#Jaccard\n",
    "def Jaccard(Node1, Node2):\n",
    "    n1 = pre_features[Node1]\n",
    "    n2 = pre_features[Node2]\n",
    "    common_neighors = list(set(n1[2]).intersection(n2[2]))\n",
    "    lm = len(common_neighors)\n",
    "    if lm == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (0.0+lm)/(len(n1[2])+len(n2[2])-lm)\n",
    "\n",
    "#Cosine\n",
    "def Cosine(Node1, Node2):\n",
    "    n1 = pre_features[Node1]\n",
    "    n2 = pre_features[Node2]\n",
    "    common_neighors = list(set(n1[2]).intersection(n2[2]))\n",
    "    lm = len(common_neighors)\n",
    "    if lm == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (0.0+lm)/(len(n1[2])*len(n2[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "#Adding feature to data\n",
    "def add_feature(d, feature):\n",
    "    data = copy.deepcopy(d)\n",
    "    for i in tqdm(range(len(data))):\n",
    "        source, slink = data[i][0]\n",
    "        for ff in feature:\n",
    "            data[i].append(ff(source, slink))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09010403cf447a195f2c453de8761cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d2d550f69544ddba0bac50178fa8176",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data_v1: \n",
    "# added feature: AA\n",
    "l = 50000\n",
    "pos_data_v1 = add_feature(pos_data[:l], [AA, Jaccard, Cosine])\n",
    "neg_data_v1 = add_feature(neg_data[:l], [AA, Jaccard, Cosine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aee4140ed7d543b29eef03997205f70d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neg_data_v1 = add_feature(neg_data[:l], [AA, Jaccard, Cosine])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_data_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1605632, 619109), 0, 0.0, 0, 0]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_data_v1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c6e5dcaf-32ef-4489-9861-4916e4ce15e6"
    }
   },
   "source": [
    "# Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(x):\n",
    "    return (1 / (1 + math.exp(-x)))\n",
    "def sigmoid_n(x):\n",
    "    return ((1 / (1 + math.exp(-x))-0.5)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbpresent": {
     "id": "1b97ae8d-bf43-468f-a859-d331c641445a"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"test-public.txt\", \"r\") as f:\n",
    "    test_data = f.readlines()\n",
    "    test_data = [i.split() for i in test_data[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "nbpresent": {
     "id": "058ed2d0-b247-4a91-b6b7-01e10da8c338"
    }
   },
   "outputs": [],
   "source": [
    "def predict(method):\n",
    "    result = []\n",
    "    for l in tqdm(range(len(test_data))):\n",
    "        line = test_data[l]\n",
    "        result.append((line[0], method(int(line[1]), int(line[2]))))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1001', '1094048', '594102']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "nbpresent": {
     "id": "c0ba79fd-aa30-42a2-ae49-2ec3d6b660d6"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aef126381f6455491b952fc3eda1354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=2000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = predict(AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination of 3 method\n",
    "mixture_result = []\n",
    "for line in test_data:\n",
    "    source = int(line[1])\n",
    "    slink = int(line[2])\n",
    "    try:\n",
    "        aa = AA(source, slink)\n",
    "        ja = Jaccard(source, slink)\n",
    "        co = Cosine(source, slink)\n",
    "    except:\n",
    "        aa = 0\n",
    "        ja = 0\n",
    "        co = 0\n",
    "    mixture_result.append([aa, ja, co])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0, 0],\n",
       " [0.4076919571196112, 0.006259780907668232, 3.909839110120619e-05],\n",
       " [0.0, 0, 0],\n",
       " [1.2374608214883451, 0.0625, 0.0024665257223396757],\n",
       " [0.8026556776069618, 0.012072434607645875, 9.646922631680494e-05],\n",
       " [2.3557421029156194, 0.013474494706448507, 0.0008437801350048216],\n",
       " [0.09064221933626666, 0.002012072434607646, 0.00012966804979253112],\n",
       " [0.15741513279199884, 0.0078125, 0.0003734129947722181],\n",
       " [0.15832403284061786, 0.003976143141153081, 7.182360123536594e-05],\n",
       " [0.0, 0, 0]]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mixture_result[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import rankdata\n",
    "aa = np.array(rankdata([i[0] for i in mixture_result]))\n",
    "ja = np.array(rankdata([i[1] for i in mixture_result]))\n",
    "co = np.array(rankdata([i[2] for i in mixture_result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score of combination model\n",
    "com_prediction = []\n",
    "order = 1\n",
    "for score in list((aa + ja + co)/np.max((aa + ja + co))):\n",
    "    com_prediction.append((order, score))\n",
    "    order += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 0.6073129251700681)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "com_prediction[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "57892d4d-c993-46f2-9644-9de528a05378"
    }
   },
   "source": [
    "## Save to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "nbpresent": {
     "id": "e0b2c69e-c30b-4c7c-9a78-5f7582cde4a1"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "'''\n",
    "Description: get time\n",
    "Input: \n",
    "Output: time\n",
    "''' \n",
    "def nowtime():\n",
    "    return time.strftime(\"%Y%m%d-%H%M\", time.localtime())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Description: Save prediction result to files\n",
    "Input: (1) result\n",
    "       (2) filename\n",
    "Output: \n",
    "\"\"\"\n",
    "def save_prediction_to_csv(result,filename):\n",
    "    headers = ['id','Prediction']\n",
    "\n",
    "    with open(filename + str(nowtime()) + \".csv\", 'w', encoding = 'utf8') as f:\n",
    "        f_csv = csv.writer(f)\n",
    "        f_csv.writerow(headers)\n",
    "        f_csv.writerows(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "nbpresent": {
     "id": "80533105-76f7-4c0f-9af3-4d5e70b84e95"
    }
   },
   "outputs": [],
   "source": [
    "save_prediction_to_csv(com_prediction, \"Xudong\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from scipy import spatial\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import Input, Embedding, LSTM, Dense\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pos_data_v1[:49000]+neg_data_v1[:49000]\n",
    "test_data = pos_data_v1[49000:]+neg_data_v1[49000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array([i[2:] for i in train_data])\n",
    "train_labels = np.array([i[1] for i in train_data])\n",
    "\n",
    "test_features = np.array([i[2:] for i in test_data])\n",
    "test_labels = np.array([i[1] for i in test_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetIterator:\n",
    "    \"\"\"\n",
    "    An iterator that returns randomized batches from a data set (with features and labels)\n",
    "    \"\"\"\n",
    "    def __init__(self, features, labels, batch_size):\n",
    "        assert(features.shape[0]==labels.shape[0])\n",
    "        assert(batch_size > 0 and batch_size <= features.shape[0])\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        self.num_instances = features.shape[0]\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batches = self.num_instances//self.batch_size\n",
    "        if (self.num_instances%self.batch_size!=0):\n",
    "            self.num_batches += 1\n",
    "        self._i = 0\n",
    "        self._rand_ids = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._i = 0\n",
    "        self._rand_ids = np.random.permutation(self.num_instances)\n",
    "        return self\n",
    "        \n",
    "    def __next__(self):\n",
    "        if self.num_instances - self._i >= self.batch_size:\n",
    "            this_rand_ids = self._rand_ids[self._i:self._i + self.batch_size]\n",
    "            self._i += self.batch_size\n",
    "            return self.features[this_rand_ids], self.labels[this_rand_ids]\n",
    "        elif self.num_instances - self._i > 0:\n",
    "            this_rand_ids = self._rand_ids[self._i::]\n",
    "            self._i = self.num_instances\n",
    "            return self.features[this_rand_ids], self.labels[this_rand_ids]\n",
    "        else:\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "98000/98000 [==============================] - 3s 28us/step - loss: 0.6246 - acc: 0.5901\n",
      "Epoch 2/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6053 - acc: 0.6021\n",
      "Epoch 3/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6023 - acc: 0.6033\n",
      "Epoch 4/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6013 - acc: 0.6036\n",
      "Epoch 5/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6011 - acc: 0.6037\n",
      "Epoch 6/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6009 - acc: 0.6038\n",
      "Epoch 7/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6008 - acc: 0.6039\n",
      "Epoch 8/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6008 - acc: 0.6038\n",
      "Epoch 9/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6007 - acc: 0.6038\n",
      "Epoch 10/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6006 - acc: 0.6039\n",
      "Epoch 11/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6008 - acc: 0.6039\n",
      "Epoch 12/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6001 - acc: 0.6039\n",
      "Epoch 13/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6008 - acc: 0.6039\n",
      "Epoch 14/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6006 - acc: 0.6039\n",
      "Epoch 15/50\n",
      "98000/98000 [==============================] - 2s 26us/step - loss: 0.6003 - acc: 0.6040\n",
      "Epoch 16/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6002 - acc: 0.6040\n",
      "Epoch 17/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6003 - acc: 0.6039\n",
      "Epoch 18/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6001 - acc: 0.6039\n",
      "Epoch 19/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6002 - acc: 0.6038\n",
      "Epoch 20/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6002 - acc: 0.6039\n",
      "Epoch 21/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6007 - acc: 0.6039\n",
      "Epoch 22/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6003 - acc: 0.6039\n",
      "Epoch 23/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6004 - acc: 0.6040\n",
      "Epoch 24/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6005 - acc: 0.6039\n",
      "Epoch 25/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6000 - acc: 0.6040\n",
      "Epoch 26/50\n",
      "98000/98000 [==============================] - 3s 27us/step - loss: 0.6003 - acc: 0.6039\n",
      "Epoch 27/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6005 - acc: 0.6040\n",
      "Epoch 28/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6001 - acc: 0.6039\n",
      "Epoch 29/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6005 - acc: 0.6039\n",
      "Epoch 30/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6002 - acc: 0.6040\n",
      "Epoch 31/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.5999 - acc: 0.6040\n",
      "Epoch 32/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6003 - acc: 0.6040\n",
      "Epoch 33/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.5997 - acc: 0.6040\n",
      "Epoch 34/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6005 - acc: 0.6040\n",
      "Epoch 35/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6001 - acc: 0.6040\n",
      "Epoch 36/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.5996 - acc: 0.6040\n",
      "Epoch 37/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6001 - acc: 0.6040\n",
      "Epoch 38/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6006 - acc: 0.6038\n",
      "Epoch 39/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6001 - acc: 0.6040\n",
      "Epoch 40/50\n",
      "98000/98000 [==============================] - 2s 26us/step - loss: 0.5998 - acc: 0.6040\n",
      "Epoch 41/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6000 - acc: 0.6040\n",
      "Epoch 42/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.5998 - acc: 0.6040\n",
      "Epoch 43/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.5997 - acc: 0.6040\n",
      "Epoch 44/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.5999 - acc: 0.6040\n",
      "Epoch 45/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.5993 - acc: 0.6040\n",
      "Epoch 46/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.5995 - acc: 0.6040\n",
      "Epoch 47/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6003 - acc: 0.6040\n",
      "Epoch 48/50\n",
      "98000/98000 [==============================] - 2s 25us/step - loss: 0.6003 - acc: 0.6040\n",
      "Epoch 49/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.6002 - acc: 0.6040\n",
      "Epoch 50/50\n",
      "98000/98000 [==============================] - 3s 26us/step - loss: 0.5996 - acc: 0.6040\n",
      "2000/2000 [==============================] - 0s 44us/step\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=3, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_features, train_labels,\n",
    "          epochs=50,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(test_features, test_labels, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_prediction = list(model.predict(np.array(mixture_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 1\n",
    "CN_prediction = []\n",
    "for i in range(2000):\n",
    "    CN_prediction.append((order, int(NN_prediction[i])))\n",
    "    order += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 1)"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CN_prediction[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_prediction_to_csv(CN_prediction, \"Xudong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
