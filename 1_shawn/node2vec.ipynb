{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_data_dir = \"../../data/\"\n",
    "def save_obj(obj, name ):\n",
    "    with open(obj_data_dir + name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(obj_data_dir + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "# load data\n",
    "# BasicFeatures = load_obj(\"pre_features\")\n",
    "training_edges=load_obj('SBdata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../../node2vec/emb/\"\n",
    "cnt=0\n",
    "flag=False\n",
    "emb_dict = {}\n",
    "with open(data_dir + \"sb_data_edges.emd\", \"r\") as f:\n",
    "    read_rows = f.readlines()\n",
    "    for row in read_rows:\n",
    "        if cnt ==0:\n",
    "            cnt+=1\n",
    "            continue\n",
    "        row_array = np.array(row.split())\n",
    "        row_vector= [float(x) for x in row_array[1:]]\n",
    "        emb_dict[int(row_array[0])]=row_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# print(cosine_similarity([1, 0, -1], [-1,-1, 0]))\n",
    "# array([[-0.5]])\n",
    "\n",
    "training_edges_cosine = []\n",
    "#  对training_data中的做cosine\n",
    "mean =0\n",
    "cnt=0\n",
    "summation=0\n",
    "for training_edge in training_edges:\n",
    "    label = int(training_edge[1])\n",
    "    source = int(training_edge[0][0])\n",
    "    sink = int(training_edge[0][1]) \n",
    "    try:\n",
    "        source_vector = np.array(emb_dict[source]).reshape(1, -1)\n",
    "        sink_vector = np.array(emb_dict[sink]).reshape(1, -1)\n",
    "        cosine_similarity_result = cosine_similarity(source_vector,sink_vector)[0]\n",
    "        cnt +=1\n",
    "        summation = cosine_similarity_result + summation\n",
    "    except KeyError:\n",
    "        cosine_similarity_result=None\n",
    "    training_edges_cosine.append((source, sink, label, cosine_similarity_result))\n",
    "mean = summation/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00620332])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean[0]\n",
    "# summation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training_edges_cosine=[]\n",
    "for edge in training_edges_cosine:\n",
    "    if edge[3] is None:\n",
    "        cosine_similarity_result=mean[0]\n",
    "    else:\n",
    "        cosine_similarity_result=edge[3][0]\n",
    "\n",
    "    final_training_edges_cosine.append((edge[0], edge[1], edge[2], cosine_similarity_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training_data = pd.DataFrame(final_training_edges_cosine)\n",
    "final_labels_df = final_training_data[2]\n",
    "final_training_data_df = final_training_data.drop(columns=2)\n",
    "# >>> df.drop(columns=['B', 'C'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_training_data_df=final_training_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   12.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.500\n",
      "Best parameters set:\n",
      "\tclf__C: 0.1\n",
      "\tclf__penalty: 'l2'\n",
      "Accuracy: 0.5130738420458046\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# 用logistic regression试试\n",
    "X=final_training_data_df\n",
    "# count=0\n",
    "# get the data and label\n",
    "y=final_labels_df\n",
    "\n",
    "# training model\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_t, X_test, y_t, y_test = train_test_split(X,y)\n",
    "X_train, X_validation, y_train, y_validation  = train_test_split(X_t,y_t)\n",
    "# Gridsearch settings\n",
    "pipeline = Pipeline([\n",
    "    ('clf', LogisticRegression())\n",
    "])\n",
    "parameters = {\n",
    "       'clf__penalty': ('l1', 'l2'),\n",
    "       'clf__C': (0.1, 1, 5),\n",
    " }\n",
    "# 1. training_df_10w running\n",
    "X_train = X_t\n",
    "y_train = y_t\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1,\n",
    "   verbose=1, scoring='roc_auc', cv=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "print('Best score: %0.3f' % grid_search.best_score_)\n",
    "print('Best parameters set:')\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print('\\t%s: %r' % (param_name, best_parameters[param_name]))\n",
    "predictions = grid_search.predict(X_test)\n",
    "print('Accuracy:', accuracy_score(y_test, predictions))\n",
    "print('Precision:', precision_score(y_test, predictions))\n",
    "print('Recall:', recall_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='SBdata'\n",
    "training_edges = load_obj(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "389478"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_edges_for_node2vec=[]\n",
    "for training_edge in training_edges:\n",
    "    label = int(training_edge[1])\n",
    "    source = int(training_edge[0][0])\n",
    "    sink = int(training_edge[0][1])\n",
    "    if label == 1:\n",
    "        ps_edges_for_node2vec.append((source, sink))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189478"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ps_edges_for_node2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "filename='ps_edges_for_node2vec_sb_data'\n",
    "with open(filename + \".txt\", 'w', encoding = 'utf8') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerows(ps_edges_for_node2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_common_neighbours(node1, node2):\n",
    "    try:\n",
    "        n1 = pre_features[node1]\n",
    "        n2 = pre_features[node2]\n",
    "        common_neighors = list(set(n1[2]).intersection(n2[2]))\n",
    "        return common_neighors\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "training_df = pd.DataFrame()\n",
    "\n",
    "# prepare dataset for ANN\n",
    "for edge in final_edges:  \n",
    "#     print(source, sink, label)\n",
    "    source = edge[0]\n",
    "    sink = edge[1]\n",
    "    label =edge[2]\n",
    "    common_neighbours = get_common_neighbours(source, sink)\n",
    "    if len(common_neighbours)>0:\n",
    "        print('hello')\n",
    "        print(len(common_neighbours))\n",
    "    if len(common_neighbours)>=100:\n",
    "        common_neighbours = common_neighbours[:100]\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "#     print(common_neighbours)\n",
    "    common_neighbours.append(label)\n",
    "    row_df = pd.DataFrame(common_neighbours)\n",
    "    training_df = training_df.append(row_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename='edges_10w'\n",
    "with open(filename + \".txt\", 'w', encoding = 'utf8') as f:\n",
    "    f_csv = csv.writer(f)\n",
    "    f_csv.writerows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"int\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3a8aaf89971d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"int\") to list"
     ]
    }
   ],
   "source": [
    "test=[1,2,3,4]\n",
    "test[:2]\n",
    "test.append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 算二级的common neighbour的个数\n",
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# in-degree statistics\n",
    "df = pd.DataFrame(BasicFeatures)\n",
    "df =  df.T\n",
    "df.rename(columns={0: 'num_of_neighbours',\n",
    "                   1: 'log_num_of_neighbours',\n",
    "                  2: 'list_of_neighbours',\n",
    "                  3: 'list_of_in_neighbours',\n",
    "                  4: 'num_of_in_neighbours',\n",
    "                  5: 'list_of_out_neighbours',\n",
    "                  6: 'num_of_out_neighbours'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_neighbours</th>\n",
       "      <th>log_num_of_neighbours</th>\n",
       "      <th>list_of_neighbours</th>\n",
       "      <th>list_of_in_neighbours</th>\n",
       "      <th>num_of_in_neighbours</th>\n",
       "      <th>list_of_out_neighbours</th>\n",
       "      <th>num_of_out_neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.910239</td>\n",
       "      <td>[20388, 3360411]</td>\n",
       "      <td>[3360411, 20388]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_of_neighbours log_num_of_neighbours list_of_neighbours  \\\n",
       "2                 2              0.910239   [20388, 3360411]   \n",
       "\n",
       "  list_of_in_neighbours num_of_in_neighbours list_of_out_neighbours  \\\n",
       "2      [3360411, 20388]                    2                     []   \n",
       "\n",
       "  num_of_out_neighbours  \n",
       "2                     0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.loc[[2]]\n",
    "new = new_df.append(df.loc[[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_of_neighbours</th>\n",
       "      <th>log_num_of_neighbours</th>\n",
       "      <th>list_of_neighbours</th>\n",
       "      <th>list_of_in_neighbours</th>\n",
       "      <th>num_of_in_neighbours</th>\n",
       "      <th>list_of_out_neighbours</th>\n",
       "      <th>num_of_out_neighbours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.910239</td>\n",
       "      <td>[20388, 3360411]</td>\n",
       "      <td>[3360411, 20388]</td>\n",
       "      <td>2</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>[1247754, 2382107, 4588320]</td>\n",
       "      <td>[4588320, 1247754, 2382107]</td>\n",
       "      <td>3</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  num_of_neighbours log_num_of_neighbours           list_of_neighbours  \\\n",
       "2                 2              0.910239             [20388, 3360411]   \n",
       "1                 3              0.721348  [1247754, 2382107, 4588320]   \n",
       "\n",
       "         list_of_in_neighbours num_of_in_neighbours list_of_out_neighbours  \\\n",
       "2             [3360411, 20388]                    2                     []   \n",
       "1  [4588320, 1247754, 2382107]                    3                     []   \n",
       "\n",
       "  num_of_out_neighbours  \n",
       "2                     0  \n",
       "1                     0  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.DataFrame()\n",
    "# 找到所有的training data中有test data中有edge的边\n",
    "for node_in_test_data in nodes_in_test_data:\n",
    "    node_in_test_data = int(node_in_test_data)\n",
    "\n",
    "    try:\n",
    "        df_row = df.loc[[node_in_test_data]]\n",
    "#         print(df_row)\n",
    "        new_df = new_df.append(df_row)\n",
    "#         print(new_df)\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "required_set = set()\n",
    "for index, row in new_df.iterrows():\n",
    "#     print(index)\n",
    "#     print(row['list_of_neighbours'])\n",
    "    required_set.add(index)\n",
    "    for node in row['list_of_neighbours']:\n",
    "        required_set.add(node)\n",
    "len(required_set)\n",
    "# 利用已经有的边生成新的训练集\n",
    "\n",
    "data_dir = \"../../data/\"\n",
    "\n",
    "with open(data_dir + \"edges.txt\", \"r\") as f:\n",
    "    read_rows = f.readlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1222124"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'set' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-7724d9771db2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_in_test_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnodes_in_test_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'set' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "len(nodes_in_test_data)\n",
    "nodes_in_test_data.astype(int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = [i.split() for i in read_rows[0:]]\n",
    "edges_of_all_test_nodes_related=list()\n",
    "\n",
    "for row in rows:\n",
    "    row[0] = int(row[0])\n",
    "    row[1] = int(row[1])\n",
    "    edge = (row[0], row[1])\n",
    "    if str(row[0]) in nodes_in_test_data or str(row[1]) in nodes_in_test_data:\n",
    "        edges_of_all_test_nodes_related.append(edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24004361"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(edges_of_all_test_nodes_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成negative sample\n",
    "for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "writerows() takes no keyword arguments",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-e6817af4cc0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mf_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0msave_prediction_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEdges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'edges'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-e6817af4cc0e>\u001b[0m in \u001b[0;36msave_prediction_to_csv\u001b[0;34m(result, filename)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mf_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m#         f_csv.writerow(headers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mf_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriterows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0msave_prediction_to_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEdges\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'edges'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: writerows() takes no keyword arguments"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "'''\n",
    "Description: get time\n",
    "Input: \n",
    "Output: time\n",
    "''' \n",
    "def nowtime():\n",
    "    return time.strftime(\"%Y%m%d-%H%M\", time.localtime())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Description: Save prediction result to files\n",
    "Input: (1) result\n",
    "       (2) filename\n",
    "Output: \n",
    "\"\"\"\n",
    "def save_prediction_to_csv(result,filename):\n",
    "#     headers = ['id','Prediction']\n",
    "    with open(filename + str(nowtime()) + \".txt\", 'w', encoding = 'utf8') as f:\n",
    "        f_csv = csv.writer(f)\n",
    "#         f_csv.writerow(headers)\n",
    "        for row in result:\n",
    "            f_csv.writerow(result)\n",
    "\n",
    "save_prediction_to_csv(Edges,'edges')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
