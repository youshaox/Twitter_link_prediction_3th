{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import time\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre\n",
    "data_dir = \"../../data/\"\n",
    "def save_obj(obj, name ):\n",
    "    with open( name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open(data_dir + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "training_data_list = load_obj(\"SBdata_all_feature-v2\")\n",
    "test_data = load_obj(\"SB_testData_all_feature-V2\")\n",
    "\n",
    "# Get the training_data_df\n",
    "training_data_df = pd.DataFrame(training_data_list) \n",
    "final_training_data_df = training_data_df.iloc[:,2:20]\n",
    "# 0.511756 0.028259\n",
    "# get the labeled data df\n",
    "final_labels_df = training_data_df.iloc[:,1]\n",
    "test_data_df = pd.DataFrame(test_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_training_data_df = rescale_min_max(final_training_data_df)\n",
    "X=final_training_data_df\n",
    "# count=0\n",
    "# get the data and label\n",
    "y=final_labels_df\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_t, X_test, y_t, y_test = train_test_split(X,y)\n",
    "x_train = X_t\n",
    "x_test = X_test\n",
    "y_train = y_t\n",
    "y_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "225000/225000 [==============================] - 10s 44us/step - loss: 0.4502 - acc: 0.7880\n",
      "Epoch 2/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.3834 - acc: 0.8272\n",
      "Epoch 3/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.3662 - acc: 0.8362\n",
      "Epoch 4/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.3560 - acc: 0.8426 1s - los\n",
      "Epoch 5/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.3529 - acc: 0.8441\n",
      "Epoch 6/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.3467 - acc: 0.8476\n",
      "Epoch 7/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.3420 - acc: 0.8514\n",
      "Epoch 8/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3390 - acc: 0.8536\n",
      "Epoch 9/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3348 - acc: 0.8557\n",
      "Epoch 10/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.3310 - acc: 0.8574\n",
      "Epoch 11/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.3281 - acc: 0.8595\n",
      "Epoch 12/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.3279 - acc: 0.8608\n",
      "Epoch 13/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.3259 - acc: 0.8627\n",
      "Epoch 14/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3248 - acc: 0.8625\n",
      "Epoch 15/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.3218 - acc: 0.8638\n",
      "Epoch 16/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.3198 - acc: 0.8648\n",
      "Epoch 17/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.3167 - acc: 0.8667\n",
      "Epoch 18/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3173 - acc: 0.8665\n",
      "Epoch 19/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.3155 - acc: 0.8677\n",
      "Epoch 20/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.3141 - acc: 0.8686\n",
      "Epoch 21/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.3116 - acc: 0.8692\n",
      "Epoch 22/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3105 - acc: 0.8704\n",
      "Epoch 23/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.3097 - acc: 0.8710\n",
      "Epoch 24/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.3086 - acc: 0.8720\n",
      "Epoch 25/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3065 - acc: 0.8726\n",
      "Epoch 26/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.3053 - acc: 0.8735\n",
      "Epoch 27/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.3059 - acc: 0.8736\n",
      "Epoch 28/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.3060 - acc: 0.8732\n",
      "Epoch 29/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3047 - acc: 0.8740\n",
      "Epoch 30/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3027 - acc: 0.8754\n",
      "Epoch 31/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3019 - acc: 0.8750\n",
      "Epoch 32/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.3018 - acc: 0.8760\n",
      "Epoch 33/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.3016 - acc: 0.8763\n",
      "Epoch 34/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2979 - acc: 0.8778\n",
      "Epoch 35/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2981 - acc: 0.8777\n",
      "Epoch 36/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2983 - acc: 0.8778\n",
      "Epoch 37/200\n",
      "225000/225000 [==============================] - 8s 38us/step - loss: 0.2971 - acc: 0.8787\n",
      "Epoch 38/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2956 - acc: 0.8787\n",
      "Epoch 39/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2952 - acc: 0.8790\n",
      "Epoch 40/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2947 - acc: 0.8801\n",
      "Epoch 41/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2949 - acc: 0.8794\n",
      "Epoch 42/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2932 - acc: 0.8801\n",
      "Epoch 43/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2927 - acc: 0.8812\n",
      "Epoch 44/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2926 - acc: 0.8809\n",
      "Epoch 45/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2911 - acc: 0.8814\n",
      "Epoch 46/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2916 - acc: 0.8817\n",
      "Epoch 47/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2913 - acc: 0.8816\n",
      "Epoch 48/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2907 - acc: 0.8825\n",
      "Epoch 49/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2899 - acc: 0.8820\n",
      "Epoch 50/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2889 - acc: 0.8831\n",
      "Epoch 51/200\n",
      "225000/225000 [==============================] - 10s 42us/step - loss: 0.2890 - acc: 0.8832\n",
      "Epoch 52/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2878 - acc: 0.8832\n",
      "Epoch 53/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2890 - acc: 0.8830\n",
      "Epoch 54/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2876 - acc: 0.8840\n",
      "Epoch 55/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2879 - acc: 0.8834\n",
      "Epoch 56/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2864 - acc: 0.8839\n",
      "Epoch 57/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2867 - acc: 0.8840\n",
      "Epoch 58/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2862 - acc: 0.8845\n",
      "Epoch 59/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2853 - acc: 0.8848\n",
      "Epoch 60/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2856 - acc: 0.8844\n",
      "Epoch 61/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2855 - acc: 0.8848\n",
      "Epoch 62/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2848 - acc: 0.8852\n",
      "Epoch 63/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2842 - acc: 0.8858\n",
      "Epoch 64/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2850 - acc: 0.8851\n",
      "Epoch 65/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2832 - acc: 0.8862\n",
      "Epoch 66/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2827 - acc: 0.8863\n",
      "Epoch 67/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2826 - acc: 0.8859\n",
      "Epoch 68/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2822 - acc: 0.8863\n",
      "Epoch 69/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2843 - acc: 0.8851\n",
      "Epoch 70/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2829 - acc: 0.8859\n",
      "Epoch 71/200\n",
      "225000/225000 [==============================] - 10s 42us/step - loss: 0.2834 - acc: 0.8866\n",
      "Epoch 72/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2828 - acc: 0.8864\n",
      "Epoch 73/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2823 - acc: 0.8861\n",
      "Epoch 74/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2814 - acc: 0.8875\n",
      "Epoch 75/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2809 - acc: 0.8873\n",
      "Epoch 76/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2808 - acc: 0.8869\n",
      "Epoch 77/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2791 - acc: 0.8883\n",
      "Epoch 78/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2799 - acc: 0.8881\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2801 - acc: 0.8880\n",
      "Epoch 80/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2798 - acc: 0.8878\n",
      "Epoch 81/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2794 - acc: 0.8872\n",
      "Epoch 82/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2799 - acc: 0.8879\n",
      "Epoch 83/200\n",
      "225000/225000 [==============================] - 8s 38us/step - loss: 0.2794 - acc: 0.8883\n",
      "Epoch 84/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2808 - acc: 0.8875\n",
      "Epoch 85/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2807 - acc: 0.8873\n",
      "Epoch 86/200\n",
      "225000/225000 [==============================] - 10s 44us/step - loss: 0.2790 - acc: 0.8886\n",
      "Epoch 87/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2779 - acc: 0.8893\n",
      "Epoch 88/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2791 - acc: 0.8878\n",
      "Epoch 89/200\n",
      "225000/225000 [==============================] - 10s 42us/step - loss: 0.2780 - acc: 0.8888\n",
      "Epoch 90/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2771 - acc: 0.8893\n",
      "Epoch 91/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2782 - acc: 0.8890\n",
      "Epoch 92/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2776 - acc: 0.8889\n",
      "Epoch 93/200\n",
      "225000/225000 [==============================] - 8s 36us/step - loss: 0.2757 - acc: 0.8899\n",
      "Epoch 94/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2764 - acc: 0.8899\n",
      "Epoch 95/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2770 - acc: 0.8901\n",
      "Epoch 96/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2770 - acc: 0.8898\n",
      "Epoch 97/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2748 - acc: 0.8903\n",
      "Epoch 98/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2751 - acc: 0.8904\n",
      "Epoch 99/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2764 - acc: 0.8898\n",
      "Epoch 100/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2754 - acc: 0.8900\n",
      "Epoch 101/200\n",
      "225000/225000 [==============================] - 8s 36us/step - loss: 0.2755 - acc: 0.8895\n",
      "Epoch 102/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2752 - acc: 0.8903\n",
      "Epoch 103/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2742 - acc: 0.8910\n",
      "Epoch 104/200\n",
      "225000/225000 [==============================] - 8s 36us/step - loss: 0.2732 - acc: 0.8914\n",
      "Epoch 105/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2747 - acc: 0.8898\n",
      "Epoch 106/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2744 - acc: 0.8910\n",
      "Epoch 107/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2733 - acc: 0.8913\n",
      "Epoch 108/200\n",
      "225000/225000 [==============================] - 8s 38us/step - loss: 0.2726 - acc: 0.8917\n",
      "Epoch 109/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2735 - acc: 0.8913\n",
      "Epoch 110/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2741 - acc: 0.8909\n",
      "Epoch 111/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2735 - acc: 0.8913\n",
      "Epoch 112/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2729 - acc: 0.8921\n",
      "Epoch 113/200\n",
      "225000/225000 [==============================] - 10s 42us/step - loss: 0.2723 - acc: 0.8918\n",
      "Epoch 114/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2728 - acc: 0.8922\n",
      "Epoch 115/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2722 - acc: 0.8917\n",
      "Epoch 116/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2725 - acc: 0.8919\n",
      "Epoch 117/200\n",
      "225000/225000 [==============================] - 8s 38us/step - loss: 0.2710 - acc: 0.8923\n",
      "Epoch 118/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2712 - acc: 0.8921\n",
      "Epoch 119/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2721 - acc: 0.8926\n",
      "Epoch 120/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2705 - acc: 0.8925\n",
      "Epoch 121/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2705 - acc: 0.8930\n",
      "Epoch 122/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2703 - acc: 0.8927\n",
      "Epoch 123/200\n",
      "225000/225000 [==============================] - 10s 42us/step - loss: 0.2693 - acc: 0.8936\n",
      "Epoch 124/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2711 - acc: 0.8923\n",
      "Epoch 125/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2696 - acc: 0.8932\n",
      "Epoch 126/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2708 - acc: 0.8930\n",
      "Epoch 127/200\n",
      "225000/225000 [==============================] - 10s 42us/step - loss: 0.2706 - acc: 0.8927\n",
      "Epoch 128/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2699 - acc: 0.8933:\n",
      "Epoch 129/200\n",
      "225000/225000 [==============================] - 8s 38us/step - loss: 0.2701 - acc: 0.8934\n",
      "Epoch 130/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2685 - acc: 0.8942\n",
      "Epoch 131/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2687 - acc: 0.8934\n",
      "Epoch 132/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2684 - acc: 0.8939\n",
      "Epoch 133/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2688 - acc: 0.8940\n",
      "Epoch 134/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2686 - acc: 0.8943\n",
      "Epoch 135/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2713 - acc: 0.8932\n",
      "Epoch 136/200\n",
      "225000/225000 [==============================] - 10s 42us/step - loss: 0.2696 - acc: 0.8934\n",
      "Epoch 137/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2681 - acc: 0.8943\n",
      "Epoch 138/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2694 - acc: 0.8937\n",
      "Epoch 139/200\n",
      "225000/225000 [==============================] - 8s 38us/step - loss: 0.2695 - acc: 0.8934: 1\n",
      "Epoch 140/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2689 - acc: 0.8939\n",
      "Epoch 141/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2675 - acc: 0.8943\n",
      "Epoch 142/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2690 - acc: 0.8939\n",
      "Epoch 143/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2688 - acc: 0.8939\n",
      "Epoch 144/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2672 - acc: 0.8945\n",
      "Epoch 145/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2675 - acc: 0.8944\n",
      "Epoch 146/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2685 - acc: 0.8936\n",
      "Epoch 147/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2683 - acc: 0.8939\n",
      "Epoch 148/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2685 - acc: 0.8940\n",
      "Epoch 149/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2664 - acc: 0.8946\n",
      "Epoch 150/200\n",
      "225000/225000 [==============================] - 10s 43us/step - loss: 0.2659 - acc: 0.8951\n",
      "Epoch 151/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2673 - acc: 0.8948\n",
      "Epoch 152/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2660 - acc: 0.8944\n",
      "Epoch 153/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2671 - acc: 0.8943\n",
      "Epoch 154/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2666 - acc: 0.8948\n",
      "Epoch 155/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2679 - acc: 0.8946\n",
      "Epoch 156/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2645 - acc: 0.8954\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2668 - acc: 0.8946\n",
      "Epoch 158/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2659 - acc: 0.8950\n",
      "Epoch 159/200\n",
      "225000/225000 [==============================] - 10s 44us/step - loss: 0.2689 - acc: 0.8937\n",
      "Epoch 160/200\n",
      "225000/225000 [==============================] - 10s 44us/step - loss: 0.2670 - acc: 0.8945\n",
      "Epoch 161/200\n",
      "225000/225000 [==============================] - 10s 46us/step - loss: 0.2663 - acc: 0.8944\n",
      "Epoch 162/200\n",
      "225000/225000 [==============================] - 11s 48us/step - loss: 0.2673 - acc: 0.8947\n",
      "Epoch 163/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2671 - acc: 0.8946\n",
      "Epoch 164/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2658 - acc: 0.8955\n",
      "Epoch 165/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2663 - acc: 0.8953\n",
      "Epoch 166/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2657 - acc: 0.8947\n",
      "Epoch 167/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2667 - acc: 0.8947\n",
      "Epoch 168/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2650 - acc: 0.8955\n",
      "Epoch 169/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2637 - acc: 0.8959\n",
      "Epoch 170/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2654 - acc: 0.8957\n",
      "Epoch 171/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2663 - acc: 0.8947\n",
      "Epoch 172/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2636 - acc: 0.8958\n",
      "Epoch 173/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2653 - acc: 0.8958\n",
      "Epoch 174/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2664 - acc: 0.8950\n",
      "Epoch 175/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2662 - acc: 0.8949\n",
      "Epoch 176/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2641 - acc: 0.8962\n",
      "Epoch 177/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2641 - acc: 0.8957\n",
      "Epoch 178/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2636 - acc: 0.8960\n",
      "Epoch 179/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2645 - acc: 0.8959\n",
      "Epoch 180/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2640 - acc: 0.8955\n",
      "Epoch 181/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2634 - acc: 0.8963\n",
      "Epoch 182/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2652 - acc: 0.8958\n",
      "Epoch 183/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2637 - acc: 0.8959\n",
      "Epoch 184/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2642 - acc: 0.8961\n",
      "Epoch 185/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2649 - acc: 0.8959\n",
      "Epoch 186/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2636 - acc: 0.8955\n",
      "Epoch 187/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2646 - acc: 0.8957\n",
      "Epoch 188/200\n",
      "225000/225000 [==============================] - 9s 41us/step - loss: 0.2637 - acc: 0.8957\n",
      "Epoch 189/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2637 - acc: 0.8956\n",
      "Epoch 190/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2655 - acc: 0.8950\n",
      "Epoch 191/200\n",
      "225000/225000 [==============================] - 9s 42us/step - loss: 0.2631 - acc: 0.8963\n",
      "Epoch 192/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2648 - acc: 0.8953\n",
      "Epoch 193/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2641 - acc: 0.8955\n",
      "Epoch 194/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2636 - acc: 0.8959\n",
      "Epoch 195/200\n",
      "225000/225000 [==============================] - 8s 37us/step - loss: 0.2628 - acc: 0.8959\n",
      "Epoch 196/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2628 - acc: 0.8961\n",
      "Epoch 197/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2632 - acc: 0.8965\n",
      "Epoch 198/200\n",
      "225000/225000 [==============================] - 9s 40us/step - loss: 0.2627 - acc: 0.8954\n",
      "Epoch 199/200\n",
      "225000/225000 [==============================] - 9s 39us/step - loss: 0.2625 - acc: 0.8969\n",
      "Epoch 200/200\n",
      "225000/225000 [==============================] - 9s 38us/step - loss: 0.2625 - acc: 0.8964\n",
      "75000/75000 [==============================] - 1s 20us/step\n"
     ]
    }
   ],
   "source": [
    "# x_train = np.random.random((1000, 20))\n",
    "# y_train = keras.utils.to_categorical(np.random.randint(10, size=(1000, 1)), num_classes=10)\n",
    "# x_test = np.random.random((100, 20))\n",
    "# y_test = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=18, activation='sigmoid'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          epochs=200,\n",
    "          batch_size=128)\n",
    "score = model.evaluate(x_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 18)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.02717537),\n",
       " (2, 0.88596547),\n",
       " (3, 0.12652813),\n",
       " (4, 0.9970193),\n",
       " (5, 0.98000115),\n",
       " (6, 0.995031),\n",
       " (7, 0.98612183),\n",
       " (8, 0.92138714),\n",
       " (9, 0.5021252),\n",
       " (10, 0.8974259),\n",
       " (11, 0.8241199),\n",
       " (12, 0.32094407),\n",
       " (13, 0.070862904),\n",
       " (14, 0.29109776),\n",
       " (15, 0.9860028),\n",
       " (16, 0.5275873),\n",
       " (17, 0.86311734),\n",
       " (18, 0.0347234),\n",
       " (19, 0.027490973),\n",
       " (20, 0.9957072),\n",
       " (21, 0.046659816),\n",
       " (22, 0.21223608),\n",
       " (23, 0.11682475),\n",
       " (24, 0.5614704),\n",
       " (25, 0.7531771),\n",
       " (26, 0.9784057),\n",
       " (27, 0.0405655),\n",
       " (28, 0.9962907),\n",
       " (29, 0.995374),\n",
       " (30, 0.95991755),\n",
       " (31, 0.39165682),\n",
       " (32, 0.116376035),\n",
       " (33, 0.5046633),\n",
       " (34, 0.99754107),\n",
       " (35, 0.068620615),\n",
       " (36, 0.9948259),\n",
       " (37, 0.05105971),\n",
       " (38, 0.95621616),\n",
       " (39, 0.097165726),\n",
       " (40, 0.5792328),\n",
       " (41, 0.2425687),\n",
       " (42, 0.97871804),\n",
       " (43, 0.23308821),\n",
       " (44, 0.9958817),\n",
       " (45, 0.90948206),\n",
       " (46, 0.23026797),\n",
       " (47, 0.027449297),\n",
       " (48, 0.7994368),\n",
       " (49, 0.99752194),\n",
       " (50, 0.902097),\n",
       " (51, 0.89438343),\n",
       " (52, 0.89034754),\n",
       " (53, 0.6772271),\n",
       " (54, 0.47129944),\n",
       " (55, 0.05377877),\n",
       " (56, 0.73753434),\n",
       " (57, 0.51240176),\n",
       " (58, 0.91035634),\n",
       " (59, 0.9261128),\n",
       " (60, 0.7668632),\n",
       " (61, 0.9948618),\n",
       " (62, 0.08065636),\n",
       " (63, 0.9304679),\n",
       " (64, 0.32158998),\n",
       " (65, 0.11465305),\n",
       " (66, 0.44446424),\n",
       " (67, 0.9019928),\n",
       " (68, 0.048200235),\n",
       " (69, 0.8819649),\n",
       " (70, 0.3603595),\n",
       " (71, 0.070313275),\n",
       " (72, 0.9584765),\n",
       " (73, 0.6619212),\n",
       " (74, 0.6309512),\n",
       " (75, 0.92819685),\n",
       " (76, 0.95829546),\n",
       " (77, 0.98926336),\n",
       " (78, 0.92819685),\n",
       " (79, 0.99194795),\n",
       " (80, 0.9522261),\n",
       " (81, 0.15502402),\n",
       " (82, 0.9437393),\n",
       " (83, 0.564416),\n",
       " (84, 0.027406693),\n",
       " (85, 0.070099875),\n",
       " (86, 0.7052064),\n",
       " (87, 0.46391985),\n",
       " (88, 0.99757296),\n",
       " (89, 0.9975649),\n",
       " (90, 0.24423842),\n",
       " (91, 0.1123584),\n",
       " (92, 0.12608133),\n",
       " (93, 0.2226754),\n",
       " (94, 0.99534506),\n",
       " (95, 0.94156045),\n",
       " (96, 0.93280065),\n",
       " (97, 0.98926336),\n",
       " (98, 0.07703102),\n",
       " (99, 0.036438234),\n",
       " (100, 0.029332073),\n",
       " (101, 0.7918256),\n",
       " (102, 0.034965105),\n",
       " (103, 0.9909458),\n",
       " (104, 0.061295014),\n",
       " (105, 0.97119665),\n",
       " (106, 0.99150157),\n",
       " (107, 0.019264938),\n",
       " (108, 0.8214626),\n",
       " (109, 0.04918119),\n",
       " (110, 0.07524703),\n",
       " (111, 0.22134072),\n",
       " (112, 0.67654395),\n",
       " (113, 0.07759303),\n",
       " (114, 0.87229633),\n",
       " (115, 0.6090809),\n",
       " (116, 0.052305475),\n",
       " (117, 0.99583685),\n",
       " (118, 0.08683206),\n",
       " (119, 0.029278772),\n",
       " (120, 0.051614158),\n",
       " (121, 0.97211456),\n",
       " (122, 0.621944),\n",
       " (123, 0.9975067),\n",
       " (124, 0.9899011),\n",
       " (125, 0.99752194),\n",
       " (126, 0.3240309),\n",
       " (127, 0.5389971),\n",
       " (128, 0.2450029),\n",
       " (129, 0.036280934),\n",
       " (130, 0.67111933),\n",
       " (131, 0.8199324),\n",
       " (132, 0.9507077),\n",
       " (133, 0.12977742),\n",
       " (134, 0.80927694),\n",
       " (135, 0.048281144),\n",
       " (136, 0.98010767),\n",
       " (137, 0.31667745),\n",
       " (138, 0.99547285),\n",
       " (139, 0.8699364),\n",
       " (140, 0.12427174),\n",
       " (141, 0.5588994),\n",
       " (142, 0.5869195),\n",
       " (143, 0.07257469),\n",
       " (144, 0.9653157),\n",
       " (145, 0.49932322),\n",
       " (146, 0.9803687),\n",
       " (147, 0.082541175),\n",
       " (148, 0.98926336),\n",
       " (149, 0.5541075),\n",
       " (150, 0.02910467),\n",
       " (151, 0.1078869),\n",
       " (152, 0.900594),\n",
       " (153, 0.97633135),\n",
       " (154, 0.997271),\n",
       " (155, 0.5397688),\n",
       " (156, 0.45209366),\n",
       " (157, 0.66808486),\n",
       " (158, 0.051130604),\n",
       " (159, 0.29355273),\n",
       " (160, 0.93992376),\n",
       " (161, 0.23791997),\n",
       " (162, 0.9975248),\n",
       " (163, 0.8115409),\n",
       " (164, 0.08983207),\n",
       " (165, 0.35863715),\n",
       " (166, 0.9812819),\n",
       " (167, 0.04614746),\n",
       " (168, 0.50578994),\n",
       " (169, 0.9689358),\n",
       " (170, 0.08312983),\n",
       " (171, 0.78577924),\n",
       " (172, 0.99428636),\n",
       " (173, 0.86110204),\n",
       " (174, 0.8482171),\n",
       " (175, 0.9898094),\n",
       " (176, 0.08532898),\n",
       " (177, 0.64327854),\n",
       " (178, 0.9799012),\n",
       " (179, 0.14957146),\n",
       " (180, 0.14793825),\n",
       " (181, 0.7081608),\n",
       " (182, 0.64271057),\n",
       " (183, 0.5956313),\n",
       " (184, 0.9953745),\n",
       " (185, 0.99739385),\n",
       " (186, 0.98986393),\n",
       " (187, 0.34034553),\n",
       " (188, 0.88974524),\n",
       " (189, 0.8984783),\n",
       " (190, 0.1673597),\n",
       " (191, 0.99721247),\n",
       " (192, 0.077908605),\n",
       " (193, 0.24002682),\n",
       " (194, 0.50167966),\n",
       " (195, 0.29860592),\n",
       " (196, 0.038154766),\n",
       " (197, 0.47014204),\n",
       " (198, 0.997543),\n",
       " (199, 0.2825469),\n",
       " (200, 0.48164374),\n",
       " (201, 0.993401),\n",
       " (202, 0.6167198),\n",
       " (203, 0.8748282),\n",
       " (204, 0.6162219),\n",
       " (205, 0.13067709),\n",
       " (206, 0.9772838),\n",
       " (207, 0.94679046),\n",
       " (208, 0.68594295),\n",
       " (209, 0.07083371),\n",
       " (210, 0.9975406),\n",
       " (211, 0.90850645),\n",
       " (212, 0.42114776),\n",
       " (213, 0.13649653),\n",
       " (214, 0.14996208),\n",
       " (215, 0.9408502),\n",
       " (216, 0.9955218),\n",
       " (217, 0.11020007),\n",
       " (218, 0.99020886),\n",
       " (219, 0.93753076),\n",
       " (220, 0.14649054),\n",
       " (221, 0.9937216),\n",
       " (222, 0.68901455),\n",
       " (223, 0.9954886),\n",
       " (224, 0.98926336),\n",
       " (225, 0.997338),\n",
       " (226, 0.9768231),\n",
       " (227, 0.9975618),\n",
       " (228, 0.9975574),\n",
       " (229, 0.041907735),\n",
       " (230, 0.11014181),\n",
       " (231, 0.97875893),\n",
       " (232, 0.99422294),\n",
       " (233, 0.07378825),\n",
       " (234, 0.99176747),\n",
       " (235, 0.10011028),\n",
       " (236, 0.11330037),\n",
       " (237, 0.029262897),\n",
       " (238, 0.9973123),\n",
       " (239, 0.9876742),\n",
       " (240, 0.1206034),\n",
       " (241, 0.1322006),\n",
       " (242, 0.1851245),\n",
       " (243, 0.989703),\n",
       " (244, 0.92811155),\n",
       " (245, 0.995764),\n",
       " (246, 0.13155274),\n",
       " (247, 0.9972057),\n",
       " (248, 0.99542576),\n",
       " (249, 0.089847),\n",
       " (250, 0.091323145),\n",
       " (251, 0.47918478),\n",
       " (252, 0.9955505),\n",
       " (253, 0.075960435),\n",
       " (254, 0.029315712),\n",
       " (255, 0.5282259),\n",
       " (256, 0.99730957),\n",
       " (257, 0.2562622),\n",
       " (258, 0.07132926),\n",
       " (259, 0.09074572),\n",
       " (260, 0.04049),\n",
       " (261, 0.73871297),\n",
       " (262, 0.9974982),\n",
       " (263, 0.14210947),\n",
       " (264, 0.9818657),\n",
       " (265, 0.76860464),\n",
       " (266, 0.03157504),\n",
       " (267, 0.9975573),\n",
       " (268, 0.92819685),\n",
       " (269, 0.684585),\n",
       " (270, 0.022536384),\n",
       " (271, 0.9203646),\n",
       " (272, 0.3248537),\n",
       " (273, 0.936088),\n",
       " (274, 0.10375573),\n",
       " (275, 0.9951918),\n",
       " (276, 0.92668414),\n",
       " (277, 0.98031884),\n",
       " (278, 0.09861883),\n",
       " (279, 0.07238192),\n",
       " (280, 0.05329162),\n",
       " (281, 0.09717179),\n",
       " (282, 0.2532853),\n",
       " (283, 0.11642488),\n",
       " (284, 0.03140866),\n",
       " (285, 0.5480924),\n",
       " (286, 0.9974058),\n",
       " (287, 0.98870975),\n",
       " (288, 0.029303584),\n",
       " (289, 0.9600038),\n",
       " (290, 0.15218784),\n",
       " (291, 0.06256335),\n",
       " (292, 0.14199805),\n",
       " (293, 0.7881584),\n",
       " (294, 0.123391464),\n",
       " (295, 0.07194345),\n",
       " (296, 0.74529517),\n",
       " (297, 0.99738973),\n",
       " (298, 0.02735174),\n",
       " (299, 0.041233685),\n",
       " (300, 0.9919144),\n",
       " (301, 0.9313892),\n",
       " (302, 0.99752253),\n",
       " (303, 0.94487643),\n",
       " (304, 0.16527465),\n",
       " (305, 0.92819685),\n",
       " (306, 0.7407978),\n",
       " (307, 0.5397128),\n",
       " (308, 0.9878064),\n",
       " (309, 0.12012971),\n",
       " (310, 0.08634695),\n",
       " (311, 0.9975617),\n",
       " (312, 0.041727006),\n",
       " (313, 0.9845145),\n",
       " (314, 0.25168794),\n",
       " (315, 0.98199224),\n",
       " (316, 0.05943838),\n",
       " (317, 0.13850129),\n",
       " (318, 0.9897029),\n",
       " (319, 0.07012994),\n",
       " (320, 0.9674352),\n",
       " (321, 0.058230013),\n",
       " (322, 0.90154696),\n",
       " (323, 0.47471893),\n",
       " (324, 0.6278207),\n",
       " (325, 0.55422723),\n",
       " (326, 0.9937265),\n",
       " (327, 0.99756867),\n",
       " (328, 0.15434334),\n",
       " (329, 0.5516017),\n",
       " (330, 0.09541917),\n",
       " (331, 0.35739592),\n",
       " (332, 0.077407286),\n",
       " (333, 0.03764664),\n",
       " (334, 0.97199947),\n",
       " (335, 0.5516858),\n",
       " (336, 0.09401625),\n",
       " (337, 0.031542227),\n",
       " (338, 0.12316644),\n",
       " (339, 0.70347786),\n",
       " (340, 0.072802395),\n",
       " (341, 0.14459519),\n",
       " (342, 0.09832703),\n",
       " (343, 0.027589798),\n",
       " (344, 0.9744133),\n",
       " (345, 0.25670016),\n",
       " (346, 0.98518133),\n",
       " (347, 0.5937957),\n",
       " (348, 0.06253176),\n",
       " (349, 0.0849041),\n",
       " (350, 0.97601056),\n",
       " (351, 0.25485367),\n",
       " (352, 0.044495594),\n",
       " (353, 0.9086375),\n",
       " (354, 0.18736356),\n",
       " (355, 0.26171598),\n",
       " (356, 0.614698),\n",
       " (357, 0.7690207),\n",
       " (358, 0.060511433),\n",
       " (359, 0.3123603),\n",
       " (360, 0.9960998),\n",
       " (361, 0.03249425),\n",
       " (362, 0.9677829),\n",
       " (363, 0.42208898),\n",
       " (364, 0.14865616),\n",
       " (365, 0.98282903),\n",
       " (366, 0.997511),\n",
       " (367, 0.96520066),\n",
       " (368, 0.10671428),\n",
       " (369, 0.8203706),\n",
       " (370, 0.050075117),\n",
       " (371, 0.12730233),\n",
       " (372, 0.6920523),\n",
       " (373, 0.6344789),\n",
       " (374, 0.106959656),\n",
       " (375, 0.5832693),\n",
       " (376, 0.99755955),\n",
       " (377, 0.12929514),\n",
       " (378, 0.99556005),\n",
       " (379, 0.100938715),\n",
       " (380, 0.03366317),\n",
       " (381, 0.09679852),\n",
       " (382, 0.70446545),\n",
       " (383, 0.061204433),\n",
       " (384, 0.7684357),\n",
       " (385, 0.1358368),\n",
       " (386, 0.93764424),\n",
       " (387, 0.079493225),\n",
       " (388, 0.90615517),\n",
       " (389, 0.20059685),\n",
       " (390, 0.6143479),\n",
       " (391, 0.6604261),\n",
       " (392, 0.6593021),\n",
       " (393, 0.13298213),\n",
       " (394, 0.92862433),\n",
       " (395, 0.9965905),\n",
       " (396, 0.080546446),\n",
       " (397, 0.9975424),\n",
       " (398, 0.10018673),\n",
       " (399, 0.9935334),\n",
       " (400, 0.9975388),\n",
       " (401, 0.33606315),\n",
       " (402, 0.111036025),\n",
       " (403, 0.99727124),\n",
       " (404, 0.47149011),\n",
       " (405, 0.10732075),\n",
       " (406, 0.99511164),\n",
       " (407, 0.87898684),\n",
       " (408, 0.99353325),\n",
       " (409, 0.21554038),\n",
       " (410, 0.9897752),\n",
       " (411, 0.69847316),\n",
       " (412, 0.14988168),\n",
       " (413, 0.04215608),\n",
       " (414, 0.95356286),\n",
       " (415, 0.92819685),\n",
       " (416, 0.040362537),\n",
       " (417, 0.56740355),\n",
       " (418, 0.15932642),\n",
       " (419, 0.039372943),\n",
       " (420, 0.2295223),\n",
       " (421, 0.865557),\n",
       " (422, 0.13654387),\n",
       " (423, 0.99755055),\n",
       " (424, 0.18410712),\n",
       " (425, 0.5541023),\n",
       " (426, 0.99754757),\n",
       " (427, 0.99755496),\n",
       " (428, 0.4640479),\n",
       " (429, 0.80754757),\n",
       " (430, 0.5641076),\n",
       " (431, 0.096042424),\n",
       " (432, 0.047061943),\n",
       " (433, 0.28142866),\n",
       " (434, 0.1651799),\n",
       " (435, 0.03405058),\n",
       " (436, 0.03525099),\n",
       " (437, 0.6177084),\n",
       " (438, 0.9900405),\n",
       " (439, 0.88960665),\n",
       " (440, 0.841028),\n",
       " (441, 0.9975431),\n",
       " (442, 0.12055699),\n",
       " (443, 0.9591859),\n",
       " (444, 0.9975459),\n",
       " (445, 0.064129025),\n",
       " (446, 0.0942607),\n",
       " (447, 0.06109712),\n",
       " (448, 0.9975253),\n",
       " (449, 0.15155187),\n",
       " (450, 0.08414526),\n",
       " (451, 0.99745125),\n",
       " (452, 0.93315333),\n",
       " (453, 0.99757296),\n",
       " (454, 0.08263885),\n",
       " (455, 0.9974158),\n",
       " (456, 0.31540167),\n",
       " (457, 0.9922185),\n",
       " (458, 0.07061795),\n",
       " (459, 0.99754757),\n",
       " (460, 0.8978871),\n",
       " (461, 0.083397135),\n",
       " (462, 0.5029872),\n",
       " (463, 0.97108275),\n",
       " (464, 0.5132367),\n",
       " (465, 0.9975573),\n",
       " (466, 0.030502843),\n",
       " (467, 0.08481096),\n",
       " (468, 0.03610662),\n",
       " (469, 0.25410816),\n",
       " (470, 0.997535),\n",
       " (471, 0.9809589),\n",
       " (472, 0.6882143),\n",
       " (473, 0.27169472),\n",
       " (474, 0.13504793),\n",
       " (475, 0.9975552),\n",
       " (476, 0.0873452),\n",
       " (477, 0.9227709),\n",
       " (478, 0.98246485),\n",
       " (479, 0.9958236),\n",
       " (480, 0.7561422),\n",
       " (481, 0.76662046),\n",
       " (482, 0.9950153),\n",
       " (483, 0.8322675),\n",
       " (484, 0.06301984),\n",
       " (485, 0.16049047),\n",
       " (486, 0.9699561),\n",
       " (487, 0.8658266),\n",
       " (488, 0.9974989),\n",
       " (489, 0.87623835),\n",
       " (490, 0.9768232),\n",
       " (491, 0.9937941),\n",
       " (492, 0.041063193),\n",
       " (493, 0.97988117),\n",
       " (494, 0.4746579),\n",
       " (495, 0.9975006),\n",
       " (496, 0.09267841),\n",
       " (497, 0.056049492),\n",
       " (498, 0.13413075),\n",
       " (499, 0.06147229),\n",
       " (500, 0.068841636),\n",
       " (501, 0.99715817),\n",
       " (502, 0.7435142),\n",
       " (503, 0.018999605),\n",
       " (504, 0.9964831),\n",
       " (505, 0.99745125),\n",
       " (506, 0.13901857),\n",
       " (507, 0.10380641),\n",
       " (508, 0.13124803),\n",
       " (509, 0.10555683),\n",
       " (510, 0.1322177),\n",
       " (511, 0.24219939),\n",
       " (512, 0.99019134),\n",
       " (513, 0.07094937),\n",
       " (514, 0.063945524),\n",
       " (515, 0.9676396),\n",
       " (516, 0.08326782),\n",
       " (517, 0.5783899),\n",
       " (518, 0.9975656),\n",
       " (519, 0.9825601),\n",
       " (520, 0.09045462),\n",
       " (521, 0.0708866),\n",
       " (522, 0.9932755),\n",
       " (523, 0.29721197),\n",
       " (524, 0.8541074),\n",
       " (525, 0.9955711),\n",
       " (526, 0.99754155),\n",
       " (527, 0.113410324),\n",
       " (528, 0.48990008),\n",
       " (529, 0.9975573),\n",
       " (530, 0.78508276),\n",
       " (531, 0.64992),\n",
       " (532, 0.9952036),\n",
       " (533, 0.6302473),\n",
       " (534, 0.031264022),\n",
       " (535, 0.5978575),\n",
       " (536, 0.9447956),\n",
       " (537, 0.9849711),\n",
       " (538, 0.99748886),\n",
       " (539, 0.908986),\n",
       " (540, 0.45759985),\n",
       " (541, 0.08625605),\n",
       " (542, 0.99756783),\n",
       " (543, 0.9975078),\n",
       " (544, 0.995057),\n",
       " (545, 0.64582807),\n",
       " (546, 0.23135157),\n",
       " (547, 0.23426683),\n",
       " (548, 0.9755697),\n",
       " (549, 0.19211043),\n",
       " (550, 0.14279167),\n",
       " (551, 0.7892382),\n",
       " (552, 0.99720436),\n",
       " (553, 0.62112266),\n",
       " (554, 0.07512152),\n",
       " (555, 0.9974976),\n",
       " (556, 0.9939452),\n",
       " (557, 0.04837668),\n",
       " (558, 0.31292295),\n",
       " (559, 0.9974101),\n",
       " (560, 0.99618703),\n",
       " (561, 0.12150376),\n",
       " (562, 0.18531115),\n",
       " (563, 0.9973449),\n",
       " (564, 0.636975),\n",
       " (565, 0.9970204),\n",
       " (566, 0.07816156),\n",
       " (567, 0.9975177),\n",
       " (568, 0.9856618),\n",
       " (569, 0.048006393),\n",
       " (570, 0.15656705),\n",
       " (571, 0.9973326),\n",
       " (572, 0.68952405),\n",
       " (573, 0.5271276),\n",
       " (574, 0.14063708),\n",
       " (575, 0.26771253),\n",
       " (576, 0.08740765),\n",
       " (577, 0.921822),\n",
       " (578, 0.66783684),\n",
       " (579, 0.98889834),\n",
       " (580, 0.08344446),\n",
       " (581, 0.9974904),\n",
       " (582, 0.4330712),\n",
       " (583, 0.8709765),\n",
       " (584, 0.9974923),\n",
       " (585, 0.7789831),\n",
       " (586, 0.09666506),\n",
       " (587, 0.8717192),\n",
       " (588, 0.9948827),\n",
       " (589, 0.08516049),\n",
       " (590, 0.99729663),\n",
       " (591, 0.29273713),\n",
       " (592, 0.18903975),\n",
       " (593, 0.9975292),\n",
       " (594, 0.66763765),\n",
       " (595, 0.99752635),\n",
       " (596, 0.039285135),\n",
       " (597, 0.65597147),\n",
       " (598, 0.07190358),\n",
       " (599, 0.6199244),\n",
       " (600, 0.91281736),\n",
       " (601, 0.32429466),\n",
       " (602, 0.21697272),\n",
       " (603, 0.37551916),\n",
       " (604, 0.9974986),\n",
       " (605, 0.46998206),\n",
       " (606, 0.7603926),\n",
       " (607, 0.21810706),\n",
       " (608, 0.08295384),\n",
       " (609, 0.9963805),\n",
       " (610, 0.7131668),\n",
       " (611, 0.9195847),\n",
       " (612, 0.99752456),\n",
       " (613, 0.1688918),\n",
       " (614, 0.052486256),\n",
       " (615, 0.36189446),\n",
       " (616, 0.45155507),\n",
       " (617, 0.6878446),\n",
       " (618, 0.11220868),\n",
       " (619, 0.06698552),\n",
       " (620, 0.9970624),\n",
       " (621, 0.19636516),\n",
       " (622, 0.66840255),\n",
       " (623, 0.17685786),\n",
       " (624, 0.030350862),\n",
       " (625, 0.6653329),\n",
       " (626, 0.99552155),\n",
       " (627, 0.031887777),\n",
       " (628, 0.4182819),\n",
       " (629, 0.14786607),\n",
       " (630, 0.5756553),\n",
       " (631, 0.95879),\n",
       " (632, 0.58939445),\n",
       " (633, 0.99550194),\n",
       " (634, 0.3868033),\n",
       " (635, 0.3615673),\n",
       " (636, 0.21436271),\n",
       " (637, 0.9133457),\n",
       " (638, 0.17836905),\n",
       " (639, 0.9975643),\n",
       " (640, 0.9674566),\n",
       " (641, 0.9794023),\n",
       " (642, 0.61975104),\n",
       " (643, 0.15365377),\n",
       " (644, 0.9961278),\n",
       " (645, 0.033701055),\n",
       " (646, 0.9952675),\n",
       " (647, 0.8091175),\n",
       " (648, 0.9737995),\n",
       " (649, 0.84977645),\n",
       " (650, 0.69838303),\n",
       " (651, 0.9627237),\n",
       " (652, 0.06957077),\n",
       " (653, 0.0542079),\n",
       " (654, 0.02682894),\n",
       " (655, 0.06143988),\n",
       " (656, 0.0343999),\n",
       " (657, 0.44201246),\n",
       " (658, 0.46370524),\n",
       " (659, 0.2822841),\n",
       " (660, 0.08422198),\n",
       " (661, 0.99473757),\n",
       " (662, 0.9676981),\n",
       " (663, 0.18937364),\n",
       " (664, 0.07103299),\n",
       " (665, 0.03784619),\n",
       " (666, 0.9975446),\n",
       " (667, 0.8795541),\n",
       " (668, 0.690602),\n",
       " (669, 0.99361044),\n",
       " (670, 0.12045214),\n",
       " (671, 0.061092015),\n",
       " (672, 0.9338133),\n",
       " (673, 0.028865332),\n",
       " (674, 0.9975574),\n",
       " (675, 0.053430356),\n",
       " (676, 0.99563074),\n",
       " (677, 0.08839105),\n",
       " (678, 0.41019663),\n",
       " (679, 0.83700264),\n",
       " (680, 0.09833448),\n",
       " (681, 0.16989574),\n",
       " (682, 0.059903648),\n",
       " (683, 0.92631996),\n",
       " (684, 0.05132447),\n",
       " (685, 0.078904085),\n",
       " (686, 0.110696815),\n",
       " (687, 0.062113866),\n",
       " (688, 0.2244531),\n",
       " (689, 0.1575469),\n",
       " (690, 0.4656628),\n",
       " (691, 0.92819685),\n",
       " (692, 0.93295914),\n",
       " (693, 0.99755967),\n",
       " (694, 0.4769959),\n",
       " (695, 0.6616914),\n",
       " (696, 0.0637303),\n",
       " (697, 0.037575282),\n",
       " (698, 0.58341205),\n",
       " (699, 0.9115043),\n",
       " (700, 0.13762437),\n",
       " (701, 0.9972391),\n",
       " (702, 0.508985),\n",
       " (703, 0.19657423),\n",
       " (704, 0.49549836),\n",
       " (705, 0.9974631),\n",
       " (706, 0.57537323),\n",
       " (707, 0.9944326),\n",
       " (708, 0.99721414),\n",
       " (709, 0.77329737),\n",
       " (710, 0.04268132),\n",
       " (711, 0.96250385),\n",
       " (712, 0.4386442),\n",
       " (713, 0.03502348),\n",
       " (714, 0.97639525),\n",
       " (715, 0.07359041),\n",
       " (716, 0.10487047),\n",
       " (717, 0.9948547),\n",
       " (718, 0.08547574),\n",
       " (719, 0.9388021),\n",
       " (720, 0.98197365),\n",
       " (721, 0.51471364),\n",
       " (722, 0.99754363),\n",
       " (723, 0.5253123),\n",
       " (724, 0.96599615),\n",
       " (725, 0.99749064),\n",
       " (726, 0.9975248),\n",
       " (727, 0.89146507),\n",
       " (728, 0.6801239),\n",
       " (729, 0.9420237),\n",
       " (730, 0.9968232),\n",
       " (731, 0.99752635),\n",
       " (732, 0.03614863),\n",
       " (733, 0.7153543),\n",
       " (734, 0.04604033),\n",
       " (735, 0.077616185),\n",
       " (736, 0.99756527),\n",
       " (737, 0.105595216),\n",
       " (738, 0.96738315),\n",
       " (739, 0.09705004),\n",
       " (740, 0.83136916),\n",
       " (741, 0.7091201),\n",
       " (742, 0.99753124),\n",
       " (743, 0.99754757),\n",
       " (744, 0.6460531),\n",
       " (745, 0.93391246),\n",
       " (746, 0.097936444),\n",
       " (747, 0.99755245),\n",
       " (748, 0.23951373),\n",
       " (749, 0.8935874),\n",
       " (750, 0.579196),\n",
       " (751, 0.8759634),\n",
       " (752, 0.99753773),\n",
       " (753, 0.036498126),\n",
       " (754, 0.11344232),\n",
       " (755, 0.92819685),\n",
       " (756, 0.022311447),\n",
       " (757, 0.99720275),\n",
       " (758, 0.6832732),\n",
       " (759, 0.23383886),\n",
       " (760, 0.80391496),\n",
       " (761, 0.11717135),\n",
       " (762, 0.97718036),\n",
       " (763, 0.9975057),\n",
       " (764, 0.9625014),\n",
       " (765, 0.11489834),\n",
       " (766, 0.07637159),\n",
       " (767, 0.7540868),\n",
       " (768, 0.15304288),\n",
       " (769, 0.9862061),\n",
       " (770, 0.092517085),\n",
       " (771, 0.39028764),\n",
       " (772, 0.10883405),\n",
       " (773, 0.96512735),\n",
       " (774, 0.076817825),\n",
       " (775, 0.04299244),\n",
       " (776, 0.797511),\n",
       " (777, 0.14028195),\n",
       " (778, 0.9515749),\n",
       " (779, 0.9973181),\n",
       " (780, 0.07841417),\n",
       " (781, 0.49903876),\n",
       " (782, 0.2590165),\n",
       " (783, 0.84453565),\n",
       " (784, 0.7189145),\n",
       " (785, 0.97381),\n",
       " (786, 0.44070303),\n",
       " (787, 0.059832614),\n",
       " (788, 0.08640125),\n",
       " (789, 0.9959151),\n",
       " (790, 0.6950485),\n",
       " (791, 0.9894617),\n",
       " (792, 0.096833706),\n",
       " (793, 0.030353859),\n",
       " (794, 0.90576535),\n",
       " (795, 0.9950329),\n",
       " (796, 0.13579638),\n",
       " (797, 0.45731133),\n",
       " (798, 0.23392305),\n",
       " (799, 0.99751616),\n",
       " (800, 0.6417143),\n",
       " (801, 0.43721873),\n",
       " (802, 0.86545575),\n",
       " (803, 0.5105611),\n",
       " (804, 0.66683173),\n",
       " (805, 0.6132914),\n",
       " (806, 0.19081222),\n",
       " (807, 0.38337085),\n",
       " (808, 0.35006714),\n",
       " (809, 0.9802238),\n",
       " (810, 0.5360767),\n",
       " (811, 0.20691547),\n",
       " (812, 0.0883812),\n",
       " (813, 0.055161174),\n",
       " (814, 0.93311596),\n",
       " (815, 0.9951591),\n",
       " (816, 0.92819685),\n",
       " (817, 0.9291907),\n",
       " (818, 0.06854748),\n",
       " (819, 0.45480978),\n",
       " (820, 0.07473416),\n",
       " (821, 0.28258243),\n",
       " (822, 0.99741626),\n",
       " (823, 0.07667791),\n",
       " (824, 0.9900411),\n",
       " (825, 0.997514),\n",
       " (826, 0.12369913),\n",
       " (827, 0.46440834),\n",
       " (828, 0.23708259),\n",
       " (829, 0.9606118),\n",
       " (830, 0.9969118),\n",
       " (831, 0.8733309),\n",
       " (832, 0.9722583),\n",
       " (833, 0.976312),\n",
       " (834, 0.5107544),\n",
       " (835, 0.063711755),\n",
       " (836, 0.9967914),\n",
       " (837, 0.10118748),\n",
       " (838, 0.2516626),\n",
       " (839, 0.21826103),\n",
       " (840, 0.82894605),\n",
       " (841, 0.44958237),\n",
       " (842, 0.15911715),\n",
       " (843, 0.9975504),\n",
       " (844, 0.961964),\n",
       " (845, 0.10074521),\n",
       " (846, 0.932799),\n",
       " (847, 0.9859191),\n",
       " (848, 0.7169411),\n",
       " (849, 0.9935334),\n",
       " (850, 0.07110823),\n",
       " (851, 0.07197217),\n",
       " (852, 0.10642817),\n",
       " (853, 0.03868624),\n",
       " (854, 0.09204203),\n",
       " (855, 0.9897029),\n",
       " (856, 0.19212523),\n",
       " (857, 0.901144),\n",
       " (858, 0.8052266),\n",
       " (859, 0.07421941),\n",
       " (860, 0.3826528),\n",
       " (861, 0.9975236),\n",
       " (862, 0.99757344),\n",
       " (863, 0.8240623),\n",
       " (864, 0.4017873),\n",
       " (865, 0.480469),\n",
       " (866, 0.9184293),\n",
       " (867, 0.90755045),\n",
       " (868, 0.11895217),\n",
       " (869, 0.056202173),\n",
       " (870, 0.9056828),\n",
       " (871, 0.9964588),\n",
       " (872, 0.49951327),\n",
       " (873, 0.9914683),\n",
       " (874, 0.98977625),\n",
       " (875, 0.6272901),\n",
       " (876, 0.93768954),\n",
       " (877, 0.044362992),\n",
       " (878, 0.18321747),\n",
       " (879, 0.96062315),\n",
       " (880, 0.9972409),\n",
       " (881, 0.08295757),\n",
       " (882, 0.99664056),\n",
       " (883, 0.8600609),\n",
       " (884, 0.28388724),\n",
       " (885, 0.033110797),\n",
       " (886, 0.15853131),\n",
       " (887, 0.6642055),\n",
       " (888, 0.9947543),\n",
       " (889, 0.9933248),\n",
       " (890, 0.6229801),\n",
       " (891, 0.9832881),\n",
       " (892, 0.970295),\n",
       " (893, 0.05474986),\n",
       " (894, 0.270975),\n",
       " (895, 0.02303954),\n",
       " (896, 0.11664388),\n",
       " (897, 0.028894179),\n",
       " (898, 0.70301163),\n",
       " (899, 0.58257955),\n",
       " (900, 0.026920633),\n",
       " (901, 0.9281946),\n",
       " (902, 0.97668284),\n",
       " (903, 0.99651307),\n",
       " (904, 0.06915279),\n",
       " (905, 0.04867423),\n",
       " (906, 0.9825423),\n",
       " (907, 0.9963689),\n",
       " (908, 0.04189955),\n",
       " (909, 0.07946013),\n",
       " (910, 0.9958573),\n",
       " (911, 0.104577206),\n",
       " (912, 0.13571692),\n",
       " (913, 0.9405316),\n",
       " (914, 0.17122923),\n",
       " (915, 0.9945437),\n",
       " (916, 0.029207334),\n",
       " (917, 0.9974923),\n",
       " (918, 0.13177676),\n",
       " (919, 0.94770926),\n",
       " (920, 0.2786685),\n",
       " (921, 0.9975688),\n",
       " (922, 0.4122707),\n",
       " (923, 0.105290964),\n",
       " (924, 0.19254631),\n",
       " (925, 0.9975406),\n",
       " (926, 0.86068636),\n",
       " (927, 0.1455162),\n",
       " (928, 0.98783225),\n",
       " (929, 0.98926336),\n",
       " (930, 0.48527178),\n",
       " (931, 0.9697524),\n",
       " (932, 0.14395973),\n",
       " (933, 0.99263364),\n",
       " (934, 0.18266182),\n",
       " (935, 0.82141864),\n",
       " (936, 0.9974916),\n",
       " (937, 0.9376538),\n",
       " (938, 0.9906184),\n",
       " (939, 0.9975056),\n",
       " (940, 0.093336746),\n",
       " (941, 0.17883314),\n",
       " (942, 0.066942036),\n",
       " (943, 0.034199446),\n",
       " (944, 0.64998925),\n",
       " (945, 0.21300848),\n",
       " (946, 0.98897225),\n",
       " (947, 0.9932388),\n",
       " (948, 0.99476707),\n",
       " (949, 0.9975412),\n",
       " (950, 0.08370864),\n",
       " (951, 0.10260266),\n",
       " (952, 0.070424795),\n",
       " (953, 0.028731214),\n",
       " (954, 0.0517122),\n",
       " (955, 0.49612585),\n",
       " (956, 0.9660918),\n",
       " (957, 0.271314),\n",
       " (958, 0.07702566),\n",
       " (959, 0.20740344),\n",
       " (960, 0.90293664),\n",
       " (961, 0.9812758),\n",
       " (962, 0.095308326),\n",
       " (963, 0.99757284),\n",
       " (964, 0.4597867),\n",
       " (965, 0.9975153),\n",
       " (966, 0.7591484),\n",
       " (967, 0.7816981),\n",
       " (968, 0.99553216),\n",
       " (969, 0.05233659),\n",
       " (970, 0.99754757),\n",
       " (971, 0.9763432),\n",
       " (972, 0.14663506),\n",
       " (973, 0.9096372),\n",
       " (974, 0.8030455),\n",
       " (975, 0.99745876),\n",
       " (976, 0.07892644),\n",
       " (977, 0.9322878),\n",
       " (978, 0.99532557),\n",
       " (979, 0.24543141),\n",
       " (980, 0.6116701),\n",
       " (981, 0.89941305),\n",
       " (982, 0.5837473),\n",
       " (983, 0.2657808),\n",
       " (984, 0.02398387),\n",
       " (985, 0.9785139),\n",
       " (986, 0.9953053),\n",
       " (987, 0.52484894),\n",
       " (988, 0.9624588),\n",
       " (989, 0.92694134),\n",
       " (990, 0.8328868),\n",
       " (991, 0.094417594),\n",
       " (992, 0.9011782),\n",
       " (993, 0.09684179),\n",
       " (994, 0.11759969),\n",
       " (995, 0.18524513),\n",
       " (996, 0.029120246),\n",
       " (997, 0.8245765),\n",
       " (998, 0.6527275),\n",
       " (999, 0.07207091),\n",
       " (1000, 0.99595934),\n",
       " ...]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def predict():\n",
    "    \"\"\"\n",
    "    make the prediction using the jaccard's coefficient\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    cnt=0\n",
    "    for row in test_data_df.iterrows():\n",
    "        row_df = pd.DataFrame(row[1]).T\n",
    "        single_result = model.predict(row_df)[0][0]\n",
    "#         print(model.predict(row_df)[0][0])\n",
    "        cnt+=1\n",
    "        result.append((cnt, single_result))\n",
    "    return result\n",
    "result = predict()\n",
    "\n",
    "# # save the result\n",
    "\n",
    "\n",
    "'''\n",
    "Description: get time\n",
    "Input: \n",
    "Output: time\n",
    "''' \n",
    "def nowtime():\n",
    "    return time.strftime(\"%Y%m%d-%H%M\", time.localtime())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Description: Save prediction result to files\n",
    "Input: (1) result\n",
    "       (2) filename\n",
    "Output: \n",
    "\"\"\"\n",
    "def save_prediction_to_csv(result,filename):\n",
    "    headers = ['id','Prediction']\n",
    "\n",
    "    with open(filename + str(nowtime()) + \".csv\", 'w', encoding = 'utf8') as f:\n",
    "        f_csv = csv.writer(f)\n",
    "        f_csv.writerow(headers)\n",
    "        f_csv.writerows(result)\n",
    "save_prediction_to_csv(result, \"shawn_ann_v1_200epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
